{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "789653bc",
   "metadata": {},
   "source": [
    "# Overdetermined least-squares problems\n",
    "\n",
    "This notebook explores three ways to solve an overdetermined least-squares problem from approximation theory (taken from Lecture 19 in Trefethen and Bau). Suppose we want to fit a degree $14$ polynomial $p(x) = c_0 + c_1 x + \\cdots + c_{14} x^{14}$ to $100$ data points $b_k = B\\exp(\\sin(4x_k))$ at equispaced points $x_1,x_2,\\ldots,x_{100}$ in $[0,1]$, where $B$ is a normalization constant so that the least squares solution has $c_{14} = 1$. Each data point gives us an equation for the $15$ unkown polynomial coefficients: the result is the $100\\times 15$ overdetermined _Vandermonde_ system $Ac=b$,\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "1 && x_1 && \\cdots && x_1^{14} \\\\\n",
    "1 && x_2 && \\cdots && x_2^{14} \\\\\n",
    "\\ddots && \\ddots &&\\vdots && \\ddots \\\\\n",
    "1 && x_{100} && \\cdots && x_{100}^{14}\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "c_0 \\\\ c_1 \\\\ \\ddots \\\\ c_{14}\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "b_1 \\\\ b_2 \\\\ \\ddots \\\\ b_{100}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "The system has more equations than unknowns and there is no unique solution. The Vandermonde matrix has full column rank but is highly ill-conditioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3744a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a55415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up least-squares problem A * c = b so that a[15] = 1\n",
    "m = 100\n",
    "n = 15\n",
    "xpts = collect(0:m-1)/(m-1)\n",
    "A = zeros(m,n)\n",
    "for k in 1:n\n",
    "    A[:,k] = xpts .^ (k-1)\n",
    "end\n",
    "b = exp.(sin.(4*xpts)) / 2006.787453080206\n",
    "\n",
    "cond(A)             # display condition number of Vandermonde matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c119a5c",
   "metadata": {},
   "source": [
    "Before we test out the three methods to solve $\\min\\|Ac-b\\|$, let's estimate the condition number of the least-squares solution $c_*$ associated with perturbations in the right-hand side, $\\kappa_{b\\rightarrow c}$, and the coefficient matrix, $\\kappa_{A\\rightarrow c}$. We'll use \"backslash\" to get the approximate least-squares solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9a95db",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = A \\ b\n",
    "y = A * c\n",
    "κ = cond(A)\n",
    "cosθ = norm(y)/norm(b)\n",
    "η = norm(A)*norm(c) / norm(y)\n",
    "κA = κ / cosθ\n",
    "κb = κ / (η * cosθ)\n",
    "display(κA)                     # display condition number for perturbations to A\n",
    "display(κb)                     # display condition number for perturbations to b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7836dd42",
   "metadata": {},
   "source": [
    "Now, let's compare the three methods to compute the least-squares solution. The least-squares solution has $a_{14} = 1$ by construction.  \n",
    "\n",
    "\n",
    "## 1. The Normal Equations\n",
    " \n",
    "This means solving $A^TAc = A^Tb$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994f8b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal equations\n",
    "cN = (A'*A) \\ (A' * b)\n",
    "abs(cN[end]-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e46d800",
   "metadata": {},
   "source": [
    "Not even a single correct digit! Computing the least-squares solution via the normal equations is unstable when the system is ill-conditioned. It is stable for restricted classes of problems, e.g., problems with bounded condition number.\n",
    "\n",
    "## 2. The Singular Value Decomposition\n",
    "\n",
    "Now, let's try diagonal reduction with the thin SVD, $A = U\\Sigma V^T$. We need to solve $\\Sigma d = U^T b$ and then $c = Vd$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1bd786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagonal reduction (SVD)\n",
    "F = svd(A)\n",
    "d = (F.U' * b) ./ F.S\n",
    "c = F.V * d\n",
    "abs(1-c[end])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22f90419",
   "metadata": {},
   "source": [
    "Seven correct digits is much better! This is about as many correct digits as we can hope for when $\\kappa_{A\\rightarrow c}\\approx 10^{10}$. The SVD approach is backward stable.\n",
    "\n",
    "## The QR Decomposition (three ways)\n",
    "\n",
    "Finally, let's compute the least-squares solution using the thin QR factorization, $A=QR$. We need to solve $Rc = Q^Tb$.\n",
    "\n",
    "First, we will compute $A = QR$ with modified Gram-Schmidt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9188ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "function mgs(A)\n",
    "    V = copy(A)\n",
    "    n = size(A,2)               # number of columns\n",
    "    R = UpperTriangular(zeros(n,n))\n",
    "    for i in 1:n\n",
    "        R[i,i] = norm(V[:,i])\n",
    "        V[:,i] = V[:, i] / R[i,i]\n",
    "        for j in i+1:n\n",
    "            R[i,j] = V[:,i]'*V[:,j]\n",
    "            V[:,j] = V[:,j] - R[i,j]*V[:,i]\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return V, R\n",
    "end\n",
    "\n",
    "# unpack Q and R from modified Gram-Schmidt\n",
    "F = mgs(A)\n",
    "Q = F[1]            # 100 x 15 ONB from Gram-Schmidt\n",
    "R = F[2]            # 15 x 15 upper triangular matrix from Gram-Schmidt\n",
    "\n",
    "# solve R * c = Q' * b\n",
    "c = R \\ (Q' * b)\n",
    "abs(1-c[end])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d312621a",
   "metadata": {},
   "source": [
    "Modified Gram-Schmidt is also performing pretty poorly here! A part of this is the loss of orthogonality in the columns of $Q$ due to ill-conditioning in $A$, exacerbated by ill-conditioning in $R$ (which has the same condition number as $A$). However, we can stabilize modified Gram-Schmidt by computing the product $Q^Tb$ in a clever way. We orthogonalize the augmented matrix $[A\\,\\, b]$ with MGS and extract the last column, which is (in exact arithmetic) $Q^T b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a93cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = mgs([A b])\n",
    "\n",
    "# unpack Q and R from modified Gram-Schmidt\n",
    "R = F[2]            # 16 x 16 upper triangular matrix from Gram-Schmidt\n",
    "Qb = R[1:n,n+1]     # extract Q'*b from the last column of ONB for augmented matrix\n",
    "R = R[1:n,1:n]      # extract R from principle n x n submatrix of triangular factor\n",
    "\n",
    "# solve R * c = Q' * b\n",
    "c = R \\ Qb\n",
    "abs(1-c[end])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac27a9bd",
   "metadata": {},
   "source": [
    "Seven digits again! We are doing almost as well as the SVD! Remarkably, this augmented MGS method is a backward stable method for computing least-squares solutions, even though MGS is not a backward stable algorithm for factoring $A=QR$.\n",
    "\n",
    "Finally, let's try out the gold standard algorithm for \"daily-use\" - Householder QR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aad83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = qr(A)\n",
    "Qb = F.Q' * b\n",
    "c = F.R \\ Qb[1:n]\n",
    "abs(1-c[end])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5281d2c0",
   "metadata": {},
   "source": [
    "Householder QR gives us about 6 digits of accuracy, which is (again) about as many correct digits as we can hope for from a least-squares problem with condition number $\\kappa_{A\\rightarrow c} \\approx 10^{10}$. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24d33a6c",
   "metadata": {},
   "source": [
    "## Beyond numerical linear algebra\n",
    "\n",
    "The ill-conditioning in this polynomial regression problem can be avoided altogether by working with \n",
    "\n",
    "* better polynomial bases than the monomials $1, x, \\ldots, x^{14}$, and\n",
    "* better sample points that equispaced points in the unit interval $[-1, 1]$.\n",
    "\n",
    "The first $15$ Chebyshev polynomials are a much better choice of basis. We can build the matrix column by column using the three term recurrence satisfied by the Chebyshev polynomials, with $T_0(x) = 1$, $T_1(x) = x$, and\n",
    "\n",
    "$$ T_{k+1}(x) = 2xT_k(x) - T_{k-1}(x).$$\n",
    "\n",
    "The roots of the Chebyshev polynomials are an excellent set of sample points to build approximations from:\n",
    "\n",
    "$$x_k = \\cos(\\pi (k + 1/2)/100), \\qquad k = 1,2,\\ldots,100.$$\n",
    "\n",
    "What is the condition number of the Vandermonde matrix associated with Chebyshev polynomials and points?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c651e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a least-squares problem A * c = b so that a[15] = 1, in Chebyshev basis\n",
    "m = 100\n",
    "n = 15\n",
    "xpts = cos.(pi*(0.5.+collect(0:m-1))/m)\n",
    "A = zeros(m,n)\n",
    "A[:,1] = ones(m,1)\n",
    "A[:,2] = xpts\n",
    "for k in 3:n\n",
    "    A[:,k] = 2*xpts.*A[:,k-1] - A[:,k-2] # xpts .^ (k-1) #\n",
    "end\n",
    "b = exp.(sin.(4*xpts)) / 2006.787453080206\n",
    "\n",
    "# condition number of Vandermonde matrix\n",
    "cond(A)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4aded3f5",
   "metadata": {},
   "source": [
    "This is really the domain of _approximation theory_: how can we represent and construct highly accurate approximations to continuous objects like functions on a computer? What bases should we employ? Where should we sample/measure our function? The now classic reference is Approximation Theory and Practice by Nick Trefethen (who happens to be the first author of our NLA textbook).\n",
    "\n",
    "If you want to check accuracy in the solution, note that we have changed the least-squares problem entirely. The least-squares solution to _this problem_ may not be normalized to $1$ at the endpoint anymore. However, we can check the condition numbers again and be confident that a backward-stable algorithm achieves about 15 digits of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7055fbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = A \\ b\n",
    "y = A * c\n",
    "κ = cond(A)\n",
    "cosθ = norm(y)/norm(b)\n",
    "η = norm(A)*norm(c) / norm(y)\n",
    "κA = κ / cosθ\n",
    "κb = κ / (η * cosθ)\n",
    "display(κA)\n",
    "display(κb) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
